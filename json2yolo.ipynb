{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_dirs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Projects\\Terrain\\Terrain Segmentation\\json2yolo.ipynb Cell 1\u001b[0m line \u001b[0;36m3\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Projects/Terrain/Terrain%20Segmentation/json2yolo.ipynb#W0sZmlsZQ%3D%3D?line=383'>384</a>\u001b[0m source \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mCOCO\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Projects/Terrain/Terrain%20Segmentation/json2yolo.ipynb#W0sZmlsZQ%3D%3D?line=385'>386</a>\u001b[0m \u001b[39mif\u001b[39;00m source \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mCOCO\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/Projects/Terrain/Terrain%20Segmentation/json2yolo.ipynb#W0sZmlsZQ%3D%3D?line=386'>387</a>\u001b[0m     convert_coco_json(\u001b[39m'\u001b[39;49m\u001b[39m../datasets/coco/annotations\u001b[39;49m\u001b[39m'\u001b[39;49m,  \u001b[39m# directory with *.json\u001b[39;49;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Projects/Terrain/Terrain%20Segmentation/json2yolo.ipynb#W0sZmlsZQ%3D%3D?line=387'>388</a>\u001b[0m                       use_segments\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Projects/Terrain/Terrain%20Segmentation/json2yolo.ipynb#W0sZmlsZQ%3D%3D?line=388'>389</a>\u001b[0m                       cls91to80\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Projects/Terrain/Terrain%20Segmentation/json2yolo.ipynb#W0sZmlsZQ%3D%3D?line=390'>391</a>\u001b[0m \u001b[39melif\u001b[39;00m source \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39minfolks\u001b[39m\u001b[39m'\u001b[39m:  \u001b[39m# Infolks https://infolks.info/\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Projects/Terrain/Terrain%20Segmentation/json2yolo.ipynb#W0sZmlsZQ%3D%3D?line=391'>392</a>\u001b[0m     convert_infolks_json(name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mout\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Projects/Terrain/Terrain%20Segmentation/json2yolo.ipynb#W0sZmlsZQ%3D%3D?line=392'>393</a>\u001b[0m                          files\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../data/sm4/json/*.json\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Projects/Terrain/Terrain%20Segmentation/json2yolo.ipynb#W0sZmlsZQ%3D%3D?line=393'>394</a>\u001b[0m                          img_path\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../data/sm4/images/\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32md:\\Projects\\Terrain\\Terrain Segmentation\\json2yolo.ipynb Cell 1\u001b[0m line \u001b[0;36m2\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Projects/Terrain/Terrain%20Segmentation/json2yolo.ipynb#W0sZmlsZQ%3D%3D?line=252'>253</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert_coco_json\u001b[39m(json_dir\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../coco/annotations/\u001b[39m\u001b[39m'\u001b[39m, use_segments\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, cls91to80\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/Projects/Terrain/Terrain%20Segmentation/json2yolo.ipynb#W0sZmlsZQ%3D%3D?line=253'>254</a>\u001b[0m     save_dir \u001b[39m=\u001b[39m make_dirs()  \u001b[39m# output directory\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Projects/Terrain/Terrain%20Segmentation/json2yolo.ipynb#W0sZmlsZQ%3D%3D?line=254'>255</a>\u001b[0m     coco80 \u001b[39m=\u001b[39m coco91_to_coco80_class()\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Projects/Terrain/Terrain%20Segmentation/json2yolo.ipynb#W0sZmlsZQ%3D%3D?line=256'>257</a>\u001b[0m     \u001b[39m# Import json\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'make_dirs' is not defined"
     ]
    }
   ],
   "source": [
    "import contextlib\n",
    "import json\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "\n",
    "from utils import *\n",
    "\n",
    "\n",
    "# Convert INFOLKS JSON file into YOLO-format labels ----------------------------\n",
    "def convert_infolks_json(name, files, img_path):\n",
    "    # Create folders\n",
    "    path = make_dirs()\n",
    "\n",
    "    # Import json\n",
    "    data = []\n",
    "    for file in glob.glob(files):\n",
    "        with open(file) as f:\n",
    "            jdata = json.load(f)\n",
    "            jdata['json_file'] = file\n",
    "            data.append(jdata)\n",
    "\n",
    "    # Write images and shapes\n",
    "    name = path + os.sep + name\n",
    "    file_id, file_name, wh, cat = [], [], [], []\n",
    "    for x in tqdm(data, desc='Files and Shapes'):\n",
    "        f = glob.glob(img_path + Path(x['json_file']).stem + '.*')[0]\n",
    "        file_name.append(f)\n",
    "        wh.append(exif_size(Image.open(f)))  # (width, height)\n",
    "        cat.extend(a['classTitle'].lower() for a in x['output']['objects'])  # categories\n",
    "\n",
    "        # filename\n",
    "        with open(name + '.txt', 'a') as file:\n",
    "            file.write('%s\\n' % f)\n",
    "\n",
    "    # Write *.names file\n",
    "    names = sorted(np.unique(cat))\n",
    "    # names.pop(names.index('Missing product'))  # remove\n",
    "    with open(name + '.names', 'a') as file:\n",
    "        [file.write('%s\\n' % a) for a in names]\n",
    "\n",
    "    # Write labels file\n",
    "    for i, x in enumerate(tqdm(data, desc='Annotations')):\n",
    "        label_name = Path(file_name[i]).stem + '.txt'\n",
    "\n",
    "        with open(path + '/labels/' + label_name, 'a') as file:\n",
    "            for a in x['output']['objects']:\n",
    "                # if a['classTitle'] == 'Missing product':\n",
    "                #    continue  # skip\n",
    "\n",
    "                category_id = names.index(a['classTitle'].lower())\n",
    "\n",
    "                # The INFOLKS bounding box format is [x-min, y-min, x-max, y-max]\n",
    "                box = np.array(a['points']['exterior'], dtype=np.float32).ravel()\n",
    "                box[[0, 2]] /= wh[i][0]  # normalize x by width\n",
    "                box[[1, 3]] /= wh[i][1]  # normalize y by height\n",
    "                box = [box[[0, 2]].mean(), box[[1, 3]].mean(), box[2] - box[0], box[3] - box[1]]  # xywh\n",
    "                if (box[2] > 0.) and (box[3] > 0.):  # if w > 0 and h > 0\n",
    "                    file.write('%g %.6f %.6f %.6f %.6f\\n' % (category_id, *box))\n",
    "\n",
    "    # Split data into train, test, and validate files\n",
    "    split_files(name, file_name)\n",
    "    write_data_data(name + '.data', nc=len(names))\n",
    "    print(f'Done. Output saved to {os.getcwd() + os.sep + path}')\n",
    "\n",
    "\n",
    "# Convert vott JSON file into YOLO-format labels -------------------------------\n",
    "def convert_vott_json(name, files, img_path):\n",
    "    # Create folders\n",
    "    path = make_dirs()\n",
    "    name = path + os.sep + name\n",
    "\n",
    "    # Import json\n",
    "    data = []\n",
    "    for file in glob.glob(files):\n",
    "        with open(file) as f:\n",
    "            jdata = json.load(f)\n",
    "            jdata['json_file'] = file\n",
    "            data.append(jdata)\n",
    "\n",
    "    # Get all categories\n",
    "    file_name, wh, cat = [], [], []\n",
    "    for i, x in enumerate(tqdm(data, desc='Files and Shapes')):\n",
    "        with contextlib.suppress(Exception):\n",
    "            cat.extend(a['tags'][0] for a in x['regions'])  # categories\n",
    "\n",
    "    # Write *.names file\n",
    "    names = sorted(pd.unique(cat))\n",
    "    with open(name + '.names', 'a') as file:\n",
    "        [file.write('%s\\n' % a) for a in names]\n",
    "\n",
    "    # Write labels file\n",
    "    n1, n2 = 0, 0\n",
    "    missing_images = []\n",
    "    for i, x in enumerate(tqdm(data, desc='Annotations')):\n",
    "\n",
    "        f = glob.glob(img_path + x['asset']['name'] + '.jpg')\n",
    "        if len(f):\n",
    "            f = f[0]\n",
    "            file_name.append(f)\n",
    "            wh = exif_size(Image.open(f))  # (width, height)\n",
    "\n",
    "            n1 += 1\n",
    "            if (len(f) > 0) and (wh[0] > 0) and (wh[1] > 0):\n",
    "                n2 += 1\n",
    "\n",
    "                # append filename to list\n",
    "                with open(name + '.txt', 'a') as file:\n",
    "                    file.write('%s\\n' % f)\n",
    "\n",
    "                # write labelsfile\n",
    "                label_name = Path(f).stem + '.txt'\n",
    "                with open(path + '/labels/' + label_name, 'a') as file:\n",
    "                    for a in x['regions']:\n",
    "                        category_id = names.index(a['tags'][0])\n",
    "\n",
    "                        # The INFOLKS bounding box format is [x-min, y-min, x-max, y-max]\n",
    "                        box = a['boundingBox']\n",
    "                        box = np.array([box['left'], box['top'], box['width'], box['height']]).ravel()\n",
    "                        box[[0, 2]] /= wh[0]  # normalize x by width\n",
    "                        box[[1, 3]] /= wh[1]  # normalize y by height\n",
    "                        box = [box[0] + box[2] / 2, box[1] + box[3] / 2, box[2], box[3]]  # xywh\n",
    "\n",
    "                        if (box[2] > 0.) and (box[3] > 0.):  # if w > 0 and h > 0\n",
    "                            file.write('%g %.6f %.6f %.6f %.6f\\n' % (category_id, *box))\n",
    "        else:\n",
    "            missing_images.append(x['asset']['name'])\n",
    "\n",
    "    print('Attempted %g json imports, found %g images, imported %g annotations successfully' % (i, n1, n2))\n",
    "    if len(missing_images):\n",
    "        print('WARNING, missing images:', missing_images)\n",
    "\n",
    "    # Split data into train, test, and validate files\n",
    "    split_files(name, file_name)\n",
    "    print(f'Done. Output saved to {os.getcwd() + os.sep + path}')\n",
    "\n",
    "\n",
    "# Convert ath JSON file into YOLO-format labels --------------------------------\n",
    "def convert_ath_json(json_dir):  # dir contains json annotations and images\n",
    "    # Create folders\n",
    "    dir = make_dirs()  # output directory\n",
    "\n",
    "    jsons = []\n",
    "    for dirpath, dirnames, filenames in os.walk(json_dir):\n",
    "        jsons.extend(\n",
    "            os.path.join(dirpath, filename)\n",
    "            for filename in [\n",
    "                f for f in filenames if f.lower().endswith('.json')\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # Import json\n",
    "    n1, n2, n3 = 0, 0, 0\n",
    "    missing_images, file_name = [], []\n",
    "    for json_file in sorted(jsons):\n",
    "        with open(json_file) as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # # Get classes\n",
    "        # try:\n",
    "        #     classes = list(data['_via_attributes']['region']['class']['options'].values())  # classes\n",
    "        # except:\n",
    "        #     classes = list(data['_via_attributes']['region']['Class']['options'].values())  # classes\n",
    "\n",
    "        # # Write *.names file\n",
    "        # names = pd.unique(classes)  # preserves sort order\n",
    "        # with open(dir + 'data.names', 'w') as f:\n",
    "        #     [f.write('%s\\n' % a) for a in names]\n",
    "\n",
    "        # Write labels file\n",
    "        for x in tqdm(data['_via_img_metadata'].values(), desc=f'Processing {json_file}'):\n",
    "            image_file = str(Path(json_file).parent / x['filename'])\n",
    "            f = glob.glob(image_file)  # image file\n",
    "            if len(f):\n",
    "                f = f[0]\n",
    "                file_name.append(f)\n",
    "                wh = exif_size(Image.open(f))  # (width, height)\n",
    "\n",
    "                n1 += 1  # all images\n",
    "                if len(f) > 0 and wh[0] > 0 and wh[1] > 0:\n",
    "                    label_file = dir + 'labels/' + Path(f).stem + '.txt'\n",
    "\n",
    "                    nlabels = 0\n",
    "                    try:\n",
    "                        with open(label_file, 'a') as file:  # write labelsfile\n",
    "                            # try:\n",
    "                            #     category_id = int(a['region_attributes']['class'])\n",
    "                            # except:\n",
    "                            #     category_id = int(a['region_attributes']['Class'])\n",
    "                            category_id = 0  # single-class\n",
    "\n",
    "                            for a in x['regions']:\n",
    "                                # bounding box format is [x-min, y-min, x-max, y-max]\n",
    "                                box = a['shape_attributes']\n",
    "                                box = np.array([box['x'], box['y'], box['width'], box['height']],\n",
    "                                               dtype=np.float32).ravel()\n",
    "                                box[[0, 2]] /= wh[0]  # normalize x by width\n",
    "                                box[[1, 3]] /= wh[1]  # normalize y by height\n",
    "                                box = [box[0] + box[2] / 2, box[1] + box[3] / 2, box[2],\n",
    "                                       box[3]]  # xywh (left-top to center x-y)\n",
    "\n",
    "                                if box[2] > 0. and box[3] > 0.:  # if w > 0 and h > 0\n",
    "                                    file.write('%g %.6f %.6f %.6f %.6f\\n' % (category_id, *box))\n",
    "                                    n3 += 1\n",
    "                                    nlabels += 1\n",
    "\n",
    "                        if nlabels == 0:  # remove non-labelled images from dataset\n",
    "                            os.system(f'rm {label_file}')\n",
    "                            # print('no labels for %s' % f)\n",
    "                            continue  # next file\n",
    "\n",
    "                        # write image\n",
    "                        img_size = 4096  # resize to maximum\n",
    "                        img = cv2.imread(f)  # BGR\n",
    "                        assert img is not None, 'Image Not Found ' + f\n",
    "                        r = img_size / max(img.shape)  # size ratio\n",
    "                        if r < 1:  # downsize if necessary\n",
    "                            h, w, _ = img.shape\n",
    "                            img = cv2.resize(img, (int(w * r), int(h * r)), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "                        ifile = dir + 'images/' + Path(f).name\n",
    "                        if cv2.imwrite(ifile, img):  # if success append image to list\n",
    "                            with open(dir + 'data.txt', 'a') as file:\n",
    "                                file.write('%s\\n' % ifile)\n",
    "                            n2 += 1  # correct images\n",
    "\n",
    "                    except Exception:\n",
    "                        os.system(f'rm {label_file}')\n",
    "                        print(f'problem with {f}')\n",
    "\n",
    "            else:\n",
    "                missing_images.append(image_file)\n",
    "\n",
    "    nm = len(missing_images)  # number missing\n",
    "    print('\\nFound %g JSONs with %g labels over %g images. Found %g images, labelled %g images successfully' %\n",
    "          (len(jsons), n3, n1, n1 - nm, n2))\n",
    "    if len(missing_images):\n",
    "        print('WARNING, missing images:', missing_images)\n",
    "\n",
    "    # Write *.names file\n",
    "    names = ['knife']  # preserves sort order\n",
    "    with open(dir + 'data.names', 'w') as f:\n",
    "        [f.write('%s\\n' % a) for a in names]\n",
    "\n",
    "    # Split data into train, test, and validate files\n",
    "    split_rows_simple(dir + 'data.txt')\n",
    "    write_data_data(dir + 'data.data', nc=1)\n",
    "    print(f'Done. Output saved to {Path(dir).absolute()}')\n",
    "\n",
    "\n",
    "def convert_coco_json(json_dir='../coco/annotations/', use_segments=False, cls91to80=False):\n",
    "    save_dir = make_dirs()  # output directory\n",
    "    coco80 = coco91_to_coco80_class()\n",
    "\n",
    "    # Import json\n",
    "    for json_file in sorted(Path(json_dir).resolve().glob('*.json')):\n",
    "        fn = Path(save_dir) / 'labels' / json_file.stem.replace('instances_', '')  # folder name\n",
    "        fn.mkdir()\n",
    "        with open(json_file) as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # Create image dict\n",
    "        images = {'%g' % x['id']: x for x in data['images']}\n",
    "        # Create image-annotations dict\n",
    "        imgToAnns = defaultdict(list)\n",
    "        for ann in data['annotations']:\n",
    "            imgToAnns[ann['image_id']].append(ann)\n",
    "\n",
    "        # Write labels file\n",
    "        for img_id, anns in tqdm(imgToAnns.items(), desc=f'Annotations {json_file}'):\n",
    "            img = images['%g' % img_id]\n",
    "            h, w, f = img['height'], img['width'], img['file_name']\n",
    "\n",
    "            bboxes = []\n",
    "            segments = []\n",
    "            for ann in anns:\n",
    "                if ann['iscrowd']:\n",
    "                    continue\n",
    "                # The COCO box format is [top left x, top left y, width, height]\n",
    "                box = np.array(ann['bbox'], dtype=np.float64)\n",
    "                box[:2] += box[2:] / 2  # xy top-left corner to center\n",
    "                box[[0, 2]] /= w  # normalize x\n",
    "                box[[1, 3]] /= h  # normalize y\n",
    "                if box[2] <= 0 or box[3] <= 0:  # if w <= 0 and h <= 0\n",
    "                    continue\n",
    "\n",
    "                cls = coco80[ann['category_id'] - 1] if cls91to80 else ann['category_id'] - 1  # class\n",
    "                box = [cls] + box.tolist()\n",
    "                if box not in bboxes:\n",
    "                    bboxes.append(box)\n",
    "                # Segments\n",
    "                if use_segments:\n",
    "                    if len(ann['segmentation']) > 1:\n",
    "                        s = merge_multi_segment(ann['segmentation'])\n",
    "                        s = (np.concatenate(s, axis=0) / np.array([w, h])).reshape(-1).tolist()\n",
    "                    else:\n",
    "                        s = [j for i in ann['segmentation'] for j in i]  # all segments concatenated\n",
    "                        s = (np.array(s).reshape(-1, 2) / np.array([w, h])).reshape(-1).tolist()\n",
    "                    s = [cls] + s\n",
    "                    if s not in segments:\n",
    "                        segments.append(s)\n",
    "\n",
    "            # Write\n",
    "            with open((fn / f).with_suffix('.txt'), 'a') as file:\n",
    "                for i in range(len(bboxes)):\n",
    "                    line = *(segments[i] if use_segments else bboxes[i]),  # cls, box or segments\n",
    "                    file.write(('%g ' * len(line)).rstrip() % line + '\\n')\n",
    "\n",
    "\n",
    "def min_index(arr1, arr2):\n",
    "    \"\"\"Find a pair of indexes with the shortest distance. \n",
    "    Args:\n",
    "        arr1: (N, 2).\n",
    "        arr2: (M, 2).\n",
    "    Return:\n",
    "        a pair of indexes(tuple).\n",
    "    \"\"\"\n",
    "    dis = ((arr1[:, None, :] - arr2[None, :, :]) ** 2).sum(-1)\n",
    "    return np.unravel_index(np.argmin(dis, axis=None), dis.shape)\n",
    "\n",
    "\n",
    "def merge_multi_segment(segments):\n",
    "    \"\"\"Merge multi segments to one list.\n",
    "    Find the coordinates with min distance between each segment,\n",
    "    then connect these coordinates with one thin line to merge all \n",
    "    segments into one.\n",
    "\n",
    "    Args:\n",
    "        segments(List(List)): original segmentations in coco's json file.\n",
    "            like [segmentation1, segmentation2,...], \n",
    "            each segmentation is a list of coordinates.\n",
    "    \"\"\"\n",
    "    s = []\n",
    "    segments = [np.array(i).reshape(-1, 2) for i in segments]\n",
    "    idx_list = [[] for _ in range(len(segments))]\n",
    "\n",
    "    # record the indexes with min distance between each segment\n",
    "    for i in range(1, len(segments)):\n",
    "        idx1, idx2 = min_index(segments[i - 1], segments[i])\n",
    "        idx_list[i - 1].append(idx1)\n",
    "        idx_list[i].append(idx2)\n",
    "\n",
    "    # use two round to connect all the segments\n",
    "    for k in range(2):\n",
    "        # forward connection\n",
    "        if k == 0:\n",
    "            for i, idx in enumerate(idx_list):\n",
    "                # middle segments have two indexes\n",
    "                # reverse the index of middle segments\n",
    "                if len(idx) == 2 and idx[0] > idx[1]:\n",
    "                    idx = idx[::-1]\n",
    "                    segments[i] = segments[i][::-1, :]\n",
    "\n",
    "                segments[i] = np.roll(segments[i], -idx[0], axis=0)\n",
    "                segments[i] = np.concatenate([segments[i], segments[i][:1]])\n",
    "                # deal with the first segment and the last one\n",
    "                if i in [0, len(idx_list) - 1]:\n",
    "                    s.append(segments[i])\n",
    "                else:\n",
    "                    idx = [0, idx[1] - idx[0]]\n",
    "                    s.append(segments[i][idx[0]:idx[1] + 1])\n",
    "\n",
    "        else:\n",
    "            for i in range(len(idx_list) - 1, -1, -1):\n",
    "                if i not in [0, len(idx_list) - 1]:\n",
    "                    idx = idx_list[i]\n",
    "                    nidx = abs(idx[1] - idx[0])\n",
    "                    s.append(segments[i][nidx:])\n",
    "    return s\n",
    "\n",
    "\n",
    "def delete_dsstore(path='../datasets'):\n",
    "    # Delete apple .DS_store files\n",
    "    from pathlib import Path\n",
    "    files = list(Path(path).rglob('.DS_store'))\n",
    "    print(files)\n",
    "    for f in files:\n",
    "        f.unlink()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    source = 'COCO'\n",
    "\n",
    "    if source == 'COCO':\n",
    "        convert_coco_json('../datasets/coco/annotations',  # directory with *.json\n",
    "                          use_segments=True,\n",
    "                          cls91to80=True)\n",
    "\n",
    "    elif source == 'infolks':  # Infolks https://infolks.info/\n",
    "        convert_infolks_json(name='out',\n",
    "                             files='../data/sm4/json/*.json',\n",
    "                             img_path='../data/sm4/images/')\n",
    "\n",
    "    elif source == 'vott':  # VoTT https://github.com/microsoft/VoTT\n",
    "        convert_vott_json(name='data',\n",
    "                          files='../../Downloads/athena_day/20190715/*.json',\n",
    "                          img_path='../../Downloads/athena_day/20190715/')  # images folder\n",
    "\n",
    "    elif source == 'ath':  # ath format\n",
    "        convert_ath_json(json_dir='../../Downloads/athena/')  # images folder\n",
    "\n",
    "    # zip results\n",
    "    # os.system('zip -r ../coco.zip ../coco')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Beta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
